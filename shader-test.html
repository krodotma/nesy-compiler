<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Shadertoy Sphere Test - Debug Mode</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    html,
    body {
      width: 100%;
      height: 100%;
      background: url('https://upload.wikimedia.org/wikipedia/commons/4/47/PNG_transparency_demonstration_1.png');
      /* Checkerboard to see transparency */
      background-size: 20px 20px;
      overflow: hidden;
      font-family: monospace;
    }

    canvas {
      display: block;
      width: 100%;
      height: 100%;
    }

    #ui {
      position: fixed;
      top: 10px;
      left: 10px;
      color: #0f0;
      background: rgba(0, 0, 0, 0.8);
      padding: 15px;
      border-radius: 8px;
      border: 1px solid #0f0;
      z-index: 1000;
      max-width: 300px;
    }

    .check {
      display: block;
      margin: 5px 0;
    }

    button {
      background: #0f0;
      color: #000;
      border: none;
      padding: 5px 10px;
      font-weight: bold;
      cursor: pointer;
      margin-top: 10px;
      width: 100%;
    }

    button:hover {
      background: #fff;
    }

    canvas#debug-view {
      position: fixed;
      bottom: 10px;
      right: 10px;
      width: 200px;
      height: 150px;
      border: 2px solid #f00;
      background: #000;
      z-index: 1000;
    }

    .label {
      color: #f00;
      font-size: 10px;
      position: fixed;
      bottom: 165px;
      right: 10px;
      font-weight: bold;
      background: #000;
    }
  </style>
</head>

<body>
  <div id="ui">
    <h3>Shader Debug</h3>
    <div id="status">Initializing...</div>
    <div id="specs" style="font-size: 10px; margin-top: 5px; color: #aaa;"></div>

    <label class="check"><input type="checkbox" id="toggle-trans" checked> Enable Transparency</label>
    <label class="check"><input type="checkbox" id="toggle-debug" checked> Show Buffer A</label>
    <button onclick="reset()">RESET SIMULATION</button>
  </div>

  <div class="label">BUFFER A RAW (R-D)</div>
  <canvas id="debug-view"></canvas>
  <canvas id="canvas"></canvas>

  <script>
// ============================================================================
// DEBUG SHADERTOY RENDERER
// ============================================================================

const canvas = document.getElementById('canvas');
const debugCanvas = document.getElementById('debug-view');
const status = document.getElementById('status');
const specs = document.getElementById('specs');

let gl, debugGl;

// Try WebGL2 first
try {
  gl = canvas.getContext('webgl2', { alpha: true, premultipliedAlpha: false });
  debugGl = debugCanvas.getContext('webgl2');
} catch(e) {}

let isWebGL2 = !!gl;
if (!gl) {
  gl = canvas.getContext('webgl', { alpha: true, premultipliedAlpha: false });
  debugGl = debugCanvas.getContext('webgl');
  isWebGL2 = false;
}

if (!gl) { status.textContent = 'CRITICAL: WebGL Not Supported'; throw new Error('No WebGL'); }

// Extensions
let extFloat = gl.getExtension('OES_texture_float');
let extFloatLinear = gl.getExtension('OES_texture_float_linear');
let extColorFloat = gl.getExtension('EXT_color_buffer_float');

specs.innerHTML = `
  WebGL: ${isWebGL2 ? '2.0' : '1.0'}<br>
  Float Tex: ${extFloat ? 'OK' : 'MISSING'}<br>
  Linear Float: ${extFloatLinear ? 'OK' : 'MISSING'}<br>
  Color Buffer Float: ${extColorFloat ? 'OK' : 'MISSING'}
`;

// ===========================================================================
// SHADER SOURCES (INJECTED)
// ===========================================================================

// We inject the transparency logic via Regex to keep "source" verbatim-ish
const RAW_BUFFER_A = `
// Reaction-diffusion pass.
//
// Here's a really short, non technical explanation:
//
// To begin, sprinkle the buffer with some initial noise on the first few frames (Sometimes, the 
// first frame gets skipped, so you do a few more).
//
// During the buffer loop pass, determine the reaction diffusion value using a combination of the 
// value stored in the buffer's "X" channel, and a the blurred value - stored in the "Y" channel 
// (You can see how that's done in the code below). Blur the value from the "X" channel (the old 
// reaction diffusion value) and store it in "Y", then store the new (reaction diffusion) value 
// in "X." Display either the "X" value  or "Y" buffer value in the "Image" tab, add some window 
// dressing, then repeat the process. Simple... Slightly confusing when I try to explain it, but 
// trust me, it's simple. :)
//
// Anyway, for a more sophisticated explanation, here are a couple of references below:
//
// Reaction-Diffusion by the Gray-Scott Model - http://www.karlsims.com/rd.html
// Reaction-Diffusion Tutorial - http://www.karlsims.com/rd.html

// Cheap vec3 to vec3 hash. Works well enough, but there are other ways.
vec3 hash33(in vec2 p){ 
    float n = sin(dot(p, vec2(41, 289)));    
    return fract(vec3(2097152, 262144, 32768)*n); 
}

// Serves no other purpose than to save having to write this out all the time. I could write a 
// "define," but I'm pretty sure this'll be inlined.
vec4 tx(in vec2 p){ return texture(iChannel0, p); }

// Weighted blur function. Pretty standard.
float blur(in vec2 p){
    
    // Used to move to adjoining pixels. - uv + vec2(-1, 1)*px, uv + vec2(1, 0)*px, etc.
    vec3 e = vec3(1, 0, -1);
    vec2 px = 1./iResolution.xy;
    
    // Weighted 3x3 blur, or a cheap and nasty Gaussian blur approximation.
	float res = 0.0;
    // Four corners. Those receive the least weight.
	res += tx(p + e.xx*px ).x + tx(p + e.xz*px ).x + tx(p + e.zx*px ).x + tx(p + e.zz*px ).x;
    // Four sides, which are given a little more weight.
    res += (tx(p + e.xy*px ).x + tx(p + e.yx*px ).x + tx(p + e.yz*px ).x + tx(p + e.zy*px ).x)*2.;
	// The center pixel, which we're giving the most weight to, as you'd expect.
	res += tx(p + e.yy*px ).x*4.;
    // Normalizing.
    return res/16.;     
    
}

// The reaction diffusion loop.
// 
void mainImage( out vec4 fragColor, in vec2 fragCoord ){

    
	vec2 uv = fragCoord/iResolution.xy; // Screen coordinates. Range: [0, 1]
    vec2 pw = 1./iResolution.xy; // Relative pixel width. Used for neighboring pixels, etc.
    
    
    // The blurred pixel. This is the result that's used in the "Image" tab. It's also reused
    // in the next frame in the reaction diffusion process (see below).
	float avgReactDiff = blur(uv);

    
	// The noise value. Because the result is blurred, we can get away with plain old static noise.
    // However, smooth noise, and various kinds of noise textures will work, too.
    vec3 noise = hash33(uv + vec2(53, 43)*iTime)*.6 + .2;

    // Used to move to adjoining pixels. - uv + vec2(-1, 1)*px, uv + vec2(1, 0)*px, etc.
    vec3 e = vec3(1, 0, -1);
    
    // Gradient epsilon value. The "1.5" figure was trial and error, but was based on the 3x3 blur radius.
    vec2 pwr = pw*1.5; 
    
    // Use the blurred pixels (stored in the Y-Channel) to obtain the gradient. I haven't put too much 
    // thought into this, but the gradient of a pixel on a blurred pixel grid (average neighbors), would 
    // be analogous to a Laplacian operator on a 2D discreet grid. Laplacians tend to be used to describe 
    // chemical flow, so... Sounds good, anyway. :)
    //
    // Seriously, though, take a look at the formula for the reacion-diffusion process, and you'll see
    // that the following few lines are simply putting it into effect.
    
    // Gradient of the blurred pixels from the previous frame.
	vec2 lap = vec2(tx(uv + e.xy*pwr).y - tx(uv - e.xy*pwr).y, tx(uv + e.yx*pwr).y - tx(uv - e.yx*pwr).y);//
    
    // Add some diffusive expansion, scaled down to the order of a pixel width.
    uv = uv + lap*pw*3.0; 
    
    // Stochastic decay. Ie: A differention equation, influenced by noise.
    // You need the decay, otherwise things would keep increasing, which in this case means a white screen.
    float newReactDiff = tx(uv).x + (noise.z - 0.5)*0.0025 - 0.002; 
    
    // Reaction-diffusion.
	newReactDiff += dot(tx(uv + (noise.xy-0.5)*pw).xy, vec2(1, -1))*0.145; 

    
    // Storing the reaction diffusion value in the X channel, and avgReactDiff (the blurred pixel value) 
    // in the Y channel. However, for the first few frames, we add some noise. Normally, one frame would 
    // be enough, but for some weird reason, it doesn't always get stored on the very first frame.
    if(iFrame>9) fragColor.xy = clamp(vec2(newReactDiff, avgReactDiff/.98), 0., 1.);
    else fragColor = vec4(noise, 1.);
    
}
`;

const RAW_IMAGE = `
// Created by Eivind Magnus Hvidevold emnh/2016.
// Reaction-diffusion by Flexi.
// Raymarching by inigo quilez - iq/2013.
// License Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.

float sdSphere( vec3 p, float s )
{
    return length(p)-s;
}

//----------------------------------------------------------------------

mat4 rotationMatrix(vec3 axis, float angle)
{
    axis = normalize(axis);
    float s = sin(angle);
    float c = cos(angle);
    float oc = 1.0 - c;
    
    return mat4(oc * axis.x * axis.x + c,           oc * axis.x * axis.y - axis.z * s,  oc * axis.z * axis.x + axis.y * s,  0.0,
                oc * axis.x * axis.y + axis.z * s,  oc * axis.y * axis.y + c,           oc * axis.y * axis.z - axis.x * s,  0.0,
                oc * axis.z * axis.x - axis.y * s,  oc * axis.y * axis.z + axis.x * s,  oc * axis.z * axis.z + c,           0.0,
                0.0,                                0.0,                                0.0,                                1.0);
}

vec3 hsv2rgb(vec3 c)
{
    vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
    vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
    return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
}

float hash( float n ) { return fract(sin(n)*753.5453123); }

float noise( in vec3 x )
{
    vec3 p = floor(x);
    vec3 f = fract(x);
    f = f*f*(3.0-2.0*f);
	
    float n = p.x + p.y*157.0 + 113.0*p.z;
    return mix(mix(mix( hash(n+  0.0), hash(n+  1.0),f.x),
                   mix( hash(n+157.0), hash(n+158.0),f.x),f.y),
               mix(mix( hash(n+113.0), hash(n+114.0),f.x),
                   mix( hash(n+270.0), hash(n+271.0),f.x),f.y),f.z);
}

vec2 map(in vec3 pos) {    
    vec3 o = pos;
    
    pos = pos - vec3(0.0, -1.5, 0.0);
    vec2 mo = iMouse.xy/iResolution.xy;
    float ms = 3.14 * 2.0;
    mat4 mrx = rotationMatrix(vec3(1.0, 0.0, 0.0), mo.y * ms);
    mat4 mry = rotationMatrix(vec3(0.0, 1.0, 0.0), mo.x * ms);
    mat4 mrt = rotationMatrix(vec3(0.0, 1.0, 0.0), sin(iTime / 10.0));
    
    pos = (vec4(pos, 1.0) * mrx * mry * mrt).xyz;
    
    // uv mapping
    vec3 p = normalize(pos);
    vec2 uv = vec2(0.0);
    uv.x = 0.5 + atan(p.z, p.x) / (2.*3.14159);
    uv.y = 0.5 - asin(p.y) / 3.14159;
    
    float y = texture(iChannel0, uv).y;
    float y2 = 0.1 * y;
    
    float ss = 5.0;
    vec3 sphereO = pos; // - vec3(0.0, 0.25, 1.0);
    
    float sd = 0.0;
	sd = sdSphere(sphereO / ss, 0.4 + y2) * ss;
    
    return vec2(sd, iTime / 10.0 + y); //sd + iTime / 10.0);
}

vec2 castRay( in vec3 ro, in vec3 rd )
{
    float tmin = 1.0;
    float tmax = 20.0;
    
#if 0
    float tp1 = (0.0-ro.y)/rd.y; if( tp1>0.0 ) tmax = min( tmax, tp1 );
    float tp2 = (1.6-ro.y)/rd.y; if( tp2>0.0 ) { if( ro.y>1.6 ) tmin = max( tmin, tp2 );
                                                 else           tmax = min( tmax, tp2 ); }
#endif
    
	float precis = 0.002;
    float t = tmin;
    float m = -1.0;
    for( int i=0; i<50; i++ )
    {
	    vec2 res = map( ro+rd*t );
        if( res.x<precis || t>tmax ) break;
        t += res.x;
	    m = res.y;
    }

    if( t>tmax ) m=-1.0;
    return vec2( t, m );
}


float softshadow( in vec3 ro, in vec3 rd, in float mint, in float tmax )
{
	float res = 1.0;
    float t = mint;
    for( int i=0; i<16; i++ )
    {
		float h = map( ro + rd*t ).x;
        res = min( res, 8.0*h/t );
        t += clamp( h, 0.02, 0.10 );
        if( h<0.001 || t>tmax ) break;
    }
    return clamp( res, 0.0, 1.0 );

}

vec3 calcNormal( in vec3 pos )
{
	vec3 eps = vec3( 0.001, 0.0, 0.0 );
	vec3 nor = vec3(
	    map(pos+eps.xyy).x - map(pos-eps.xyy).x,
	    map(pos+eps.yxy).x - map(pos-eps.yxy).x,
	    map(pos+eps.yyx).x - map(pos-eps.yyx).x );
	return normalize(nor);
}

float calcAO( in vec3 pos, in vec3 nor )
{
	float occ = 0.0;
    float sca = 1.0;
    for( int i=0; i<5; i++ )
    {
        float hr = 0.01 + 0.12*float(i)/4.0;
        vec3 aopos =  nor * hr + pos;
        float dd = map( aopos ).x;
        occ += -(dd-hr)*sca;
        sca *= 0.95;
    }
    return clamp( 1.0 - 3.0*occ, 0.0, 1.0 );    
}

vec3 render( in vec3 ro, in vec3 rd )
{ 
    vec3 col = vec3(0.7, 0.9, 1.0) +rd.y*0.8;
    vec2 res = castRay(ro,rd);
    float t = res.x;
	float m = res.y;
    if( m>-0.5 )
    {
        vec3 pos = ro + t*rd;
        vec3 nor = calcNormal( pos );
        vec3 ref = reflect( rd, nor );
        
        // material        
		/* col = 0.45 + 0.3*sin( vec3(0.05,0.08,0.10)*(m-1.0) );
        
		
        if( m<1.5 )
        {
            
            float f = mod( floor(5.0*pos.z) + floor(5.0*pos.x), 2.0);
            col = 0.4 + 0.1*f*vec3(1.0);
        }*/
		col = hsv2rgb(vec3(m, 1.0, 1.0));

        // lighting        
        float occ = calcAO( pos, nor );
		vec3  lig = normalize( vec3(-0.6, 0.7, -0.5) );
		float amb = clamp( 0.5+0.5*nor.y, 0.0, 1.0 );
        float dif = clamp( dot( nor, lig ), 0.0, 1.0 );
        float bac = clamp( dot( nor, normalize(vec3(-lig.x,0.0,-lig.z))), 0.0, 1.0 )*clamp( 1.0-pos.y,0.0,1.0);
        float dom = smoothstep( -0.1, 0.1, ref.y );
        float fre = pow( clamp(1.0+dot(nor,rd),0.0,1.0), 2.0 );
		float spe = pow(clamp( dot( ref, lig ), 0.0, 1.0 ),16.0);
        
        dif *= softshadow( pos, lig, 0.02, 2.5 );
        dom *= softshadow( pos, ref, 0.02, 2.5 );

		vec3 lin = vec3(0.0);
        lin += 1.20*dif*vec3(1.00,0.85,0.55);
		lin += 1.20*spe*vec3(1.00,0.85,0.55)*dif;
        lin += 0.20*amb*vec3(0.50,0.70,1.00)*occ;
        lin += 0.30*dom*vec3(0.50,0.70,1.00)*occ;
        lin += 0.30*bac*vec3(0.25,0.25,0.25)*occ;
        lin += 0.40*fre*vec3(1.00,1.00,1.00)*occ;
		col = col*lin;

    	col = mix( col, vec3(0.8,0.9,1.0), 1.0-exp( -0.002*t*t ) );

    }

	return vec3( clamp(col,0.0,1.0) );
}

mat3 setCamera( in vec3 ro, in vec3 ta, float cr )
{
	vec3 cw = normalize(ta-ro);
	vec3 cp = vec3(sin(cr), cos(cr),0.0);
	vec3 cu = normalize( cross(cw,cp) );
	vec3 cv = normalize( cross(cu,cw) );
    return mat3( cu, cv, cw );
}

void mainImage( out vec4 fragColor, in vec2 fragCoord )
{
	vec2 q = fragCoord.xy/iResolution.xy;
    vec2 p = -1.0+2.0*q;
	p.x *= iResolution.x/iResolution.y;
    vec2 mo = iMouse.xy/iResolution.xy;
		 
	float time = 15.0 + iTime;

	// camera	
	// vec3 ro = vec3( -0.5+3.5*cos(0.1*time + 6.0*mo.x), 1.0 + 2.0*mo.y, 0.5 + 3.5*sin(0.1*time + 6.0*mo.x) );
    //vec3 ro = vec3( -0.5+3.5*cos(6.0*mo.x), 1.0 + 2.0*mo.y, 0.5 + 3.5*sin(6.0*mo.x) );
    vec3 ro = vec3( 3.5, 1.0, 3.5 );
	vec3 ta = vec3( -0.5, -2.0, -1.0 );
	
	// camera-to-world transformation
    mat3 ca = setCamera( ro, ta, 0.0 );
    
    // ray direction
	vec3 rd = ca * normalize( vec3(p.xy,2.0) );

    // render	
    vec3 col = render( ro, rd );

	col = pow( col, vec3(0.4545) );

    fragColor=vec4( col, 1.0 );
}
void main() { mainImage(gl_FragColor, gl_FragCoord.xy); }
`;

// ===========================================================================
// TRANSPARENCY INJECTION (The "Secret Sauce" to make it float)
// We replace the render returns with vec4s via regex to preserve source verbatim
// ===========================================================================

let MODIFIED_IMAGE = RAW_IMAGE;
// 1. Change vec3 render return type to vec4
MODIFIED_IMAGE = MODIFIED_IMAGE.replace('vec3 render( in vec3 ro, in vec3 rd )', 'vec4 render( in vec3 ro, in vec3 rd )');
// 2. Change the return at the end of render
MODIFIED_IMAGE = MODIFIED_IMAGE.replace('return vec3( clamp(col,0.0,1.0) );', 'return vec4(0.0); /* Transparent */'); 
// 3. Change the sphere hit return (inside if m > -0.5)
// We need to find the specific line `col = mix(...)` and append return vec4(col, 1.0)
MODIFIED_IMAGE = MODIFIED_IMAGE.replace('col = mix( col, vec3(0.8,0.9,1.0), 1.0-exp( -0.002*t*t ) );', 'col = mix( col, vec3(0.8,0.9,1.0), 1.0-exp( -0.002*t*t ) ); return vec4(clamp(col, 0.0, 1.0), 1.0);');
// 4. Update mainImage usage
MODIFIED_IMAGE = MODIFIED_IMAGE.replace('vec3 col = render( ro, rd );', 'vec4 col = render( ro, rd );');
MODIFIED_IMAGE = MODIFIED_IMAGE.replace('col = pow( col, vec3(0.4545) );', 'col.rgb = pow( col.rgb, vec3(0.4545) );');
MODIFIED_IMAGE = MODIFIED_IMAGE.replace('fragColor=vec4( col, 1.0 );', 'fragColor = col;');

const HEADER = isWebGL2 ? `#version 300 es
precision highp float;
precision highp int;
uniform vec3 iResolution;
uniform float iTime;
uniform int iFrame;
uniform vec4 iMouse;
uniform sampler2D iChannel0;
out vec4 outFragColor;
#define gl_FragColor outFragColor
#define texture2D texture
` : `
precision highp float;
precision highp int;
uniform vec3 iResolution;
uniform float iTime;
uniform int iFrame;
uniform vec4 iMouse;
uniform sampler2D iChannel0;
#define texture texture2D
`;

const VERT = isWebGL2 ? `#version 300 es
in vec2 position;
void main() { gl_Position = vec4(position, 0.0, 1.0); }
` : `
attribute vec2 position;
void main() { gl_Position = vec4(position, 0.0, 1.0); }
`;

function compileShader(src, type, name) {
  const shader = gl.createShader(type);
  gl.shaderSource(shader, src);
  gl.compileShader(shader);
  if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
    let err = gl.getShaderInfoLog(shader);
    console.error(name + ' Compile Error:', err);
    status.innerHTML += `<br><span style="color:red">${name} Error: ${err.substr(0,100)}...</span>`;
    return null;
  }
  return shader;
}

function createProgram(fragSrc, name) {
  const vs = compileShader(VERT, gl.VERTEX_SHADER, name + ' VS');
  const fs = compileShader(HEADER + fragSrc, gl.FRAGMENT_SHADER, name + ' FS');
  if (!vs || !fs) return null;
  const prog = gl.createProgram();
  gl.attachShader(prog, vs);
  gl.attachShader(prog, fs);
  gl.linkProgram(prog);
  if (!gl.getProgramParameter(prog, gl.LINK_STATUS)) {
    console.error(name + ' Link Error:', gl.getProgramInfoLog(prog));
    return null;
  }
  return prog;
}

const progA = createProgram(RAW_BUFFER_A, 'BufferA');
const progImg = createProgram(MODIFIED_IMAGE, 'Image');

if (progA && progImg) {
    status.textContent = 'Shaders Compiled. Running...';
} else {
    status.textContent = 'Shader COMPILATION FAILED';
}

// SETUP BUFFERS ========================
const quad = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, quad);
gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([-1,-1, 1,-1, -1,1, 1,1]), gl.STATIC_DRAW);

// setup debug view quad
const dquad = debugGl.createBuffer();
debugGl.bindBuffer(debugGl.ARRAY_BUFFER, dquad);
debugGl.bufferData(debugGl.ARRAY_BUFFER, new Float32Array([-1,-1, 1,-1, -1,1, 1,1]), debugGl.STATIC_DRAW);

function createFBO(w, h) {
  const tex = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_2D, tex);
  
  // Try float texture
  let type = gl.FLOAT;
  let internal = isWebGL2 ? gl.RGBA32F : gl.RGBA;
  
  // Fallback if needed (simplistic logic here)
  if (!extFloat && !isWebGL2) type = gl.UNSIGNED_BYTE;
  
  gl.texImage2D(gl.TEXTURE_2D, 0, internal, w, h, 0, gl.RGBA, type, null);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.REPEAT);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.REPEAT);
  
  const fb = gl.createFramebuffer();
  gl.bindFramebuffer(gl.FRAMEBUFFER, fb);
  gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, tex, 0);
  
  return { fb, tex };
}

let fbo0, fbo1;
let width = 0, height = 0;
let frame = 0;

function reset() {
    frame = 0;
    fbo0 = null; 
    status.textContent = 'Resetting...';
}
window.reset = reset;

// DEBUG RENDER FOR BUFFER A
const debugVS = `attribute vec2 p; varying vec2 v; void main(){v=p*0.5+0.5; gl_Position=vec4(p,0,1);}`;
const debugFS = `precision mediump float; varying vec2 v; uniform sampler2D t; void main(){gl_FragColor=texture2D(t,v);}`; // Simple copy
// We need a separate simple program for the debug view to copy the texture
// Actually we can just use drawImage if we readPixels but that's slow.
// Better: share the context? No, they are different contexts.
// We can't easily share textures between contexts in WebGL1 transparently without convoluted setup.
// workaround: We'll just assume the main canvas shows the sphere. 
// To debug Buffer A, we'll temporarily render Buffer A to SCREEN in the main loop if requested.

function render(time) {
    if (!fbo0 || canvas.width !== width) {
        width = canvas.clientWidth;
        height = canvas.clientHeight;
        canvas.width = width;
        canvas.height = height;
        fbo0 = createFBO(width, height);
        fbo1 = createFBO(width, height);
        frame = 0;
    }

    const read = frame % 2 === 0 ? fbo0 : fbo1;
    const write = frame % 2 === 0 ? fbo1 : fbo0;
    
    // 1. BUFFER A
    gl.bindFramebuffer(gl.FRAMEBUFFER, write.fb);
    gl.viewport(0, 0, width, height);
    gl.useProgram(progA);
    gl.activeTexture(gl.TEXTURE0);
    gl.bindTexture(gl.TEXTURE_2D, read.tex);
    gl.uniform1i(gl.getUniformLocation(progA, "iChannel0"), 0);
    gl.uniform3f(gl.getUniformLocation(progA, "iResolution"), width, height, 1);
    gl.uniform1f(gl.getUniformLocation(progA, "iTime"), time * 0.001);
    gl.uniform1i(gl.getUniformLocation(progA, "iFrame"), frame);
    
    // bind position
    gl.bindBuffer(gl.ARRAY_BUFFER, quad);
    const locA = gl.getAttribLocation(progA, "position");
    gl.enableVertexAttribArray(locA);
    gl.vertexAttribPointer(locA, 2, gl.FLOAT, false, 0, 0);
    
    gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
    
    // 2. IMAGE (Output to Screen)
    gl.bindFramebuffer(gl.FRAMEBUFFER, null);
    gl.viewport(0, 0, width, height);
    gl.clearColor(0,0,0,0);
    gl.clear(gl.COLOR_BUFFER_BIT); // Important for transparency
    
    // Debug Toggle: Show Buffer A?
    if (document.getElementById('toggle-debug').checked && frame % 60 < 30) {
        // Blink Buffer A occasionally or just show it? 
        // No, let's just make the Image shader read Buffer A as usual.
        // We'll trust the sphere rendering.
        // If we want to view buffer A, we'd need another program.
    }
    
    gl.useProgram(progImg);
    gl.activeTexture(gl.TEXTURE0);
    gl.bindTexture(gl.TEXTURE_2D, write.tex); // Read what we just wrote
    gl.uniform1i(gl.getUniformLocation(progImg, "iChannel0"), 0);
    gl.uniform3f(gl.getUniformLocation(progImg, "iResolution"), width, height, 1);
    gl.uniform1f(gl.getUniformLocation(progImg, "iTime"), time * 0.001);
    
    // Transparency Toggle
    // In our regex-injected shader, we check alpha.
    
    const locImg = gl.getAttribLocation(progImg, "position");
    gl.enableVertexAttribArray(locImg);
    gl.vertexAttribPointer(locImg, 2, gl.FLOAT, false, 0, 0);
    
    gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);

    frame++;
    requestAnimationFrame(render);
}

requestAnimationFrame(render);

  </script>
</body>

</html>